# -*- coding: utf-8 -*-
"""Alzheimer

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s1uT9OOXkUOyY_-fc3RWPqghhtS5Xm8k
"""

# Commented out IPython magic to ensure Python compatibility.
#Imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import pylab
import tensorflow as tf
from sklearn import svm
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.datasets import make_classification
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier , RandomForestRegressor
from sklearn.ensemble import AdaBoostClassifier ,GradientBoostingClassifier, GradientBoostingRegressor , AdaBoostRegressor
import xgboost
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, roc_curve, roc_auc_score
from sklearn.metrics import mean_absolute_error ,mean_squared_error ,r2_score , confusion_matrix
import sklearn
!pip install pycaret[models]
from pycaret.regression import *

#load GPU fr better testing
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
    # Currently, memory growth needs to be the same across GPUs
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        logical_gpus = tf.config.list_logical_devices('GPU')
        print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
    except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
        print(e)

#load Data
data=pd.read_csv('/content/sample_data/Data.csv', delimiter=',')
selectiveData=data.copy()

data

null=pd.isnull(data).sum()
null.head

sns.heatmap(data.corr(), annot=True)

columns_titles = list(data.columns)[3:]
for a in range (11):
  plt.hist(data.iloc[:,3+a])
  plt.title(columns_titles[a])
  plt.show()

sns.boxplot(y='Gender', x='CreditScore', hue='Exited', data=data)
plt.title('CreditScore i Gender')
plt.show()

sns.boxplot(y='Balance', x='NumOfProducts', hue='Exited', data=data)
plt.title('Balance i NumOfProducts')
plt.show()

sns.boxplot(y='Geography', x='Age', hue='Exited', data=data)
plt.title('Geography i Age')
plt.show()

sns.boxplot(y='Tenure', x='IsActiveMember', hue='Exited', data=data)
plt.title('Tenure i IsActiveMember')
plt.show()

sns.boxplot(y='EstimatedSalary', x='NumOfProducts', hue='Exited', data=data)
plt.title('EstimatedSalary i NumOfProducts')
plt.show()

sns.boxplot(y='CreditScore', x='NumOfProducts', hue='Exited', data=data)
plt.title('CreditScore i NumOfProducts')
plt.show()

clf1 = setup(data = data, target = 'Exited', feature_selection = True)

data.describe()

data['Exited'].value_counts()

data.drop(columns = ['Surname'],axis = 1,  inplace = True)

data

gender= data['Gender']
geography= data['Geography']

# for var in ['Geography']:
#     data = pd.get_dummies(data, prefix = var, columns = [var], drop_first = False)

data.drop(columns = ['Gender','Geography'],axis = 1,  inplace = True)

data

# from sklearn.preprocessing import MinMaxScaler
# scaler= MinMaxScaler()
# data=scaler.fit_transform(data)

#data=pd.DataFrame(data,columns=['CreditScore',	'Age',	'Tenure','Balance',	'NumOfProducts',	'HasCrCard',	'IsActiveMember',	'EstimatedSalary',	'Exited'])
data['CreditScore']=data['CreditScore']/max(data['CreditScore'])

data['Male'] = gender.map(lambda x : 0 if x == 'Female' else 1)
data['Male'] = data['Male'].astype('int64')

data['Germany'] = geography.map(lambda x : 1 if x == 'Germany' else 0)
data['Germany'] = data['Germany'].astype('int64')

data['France'] = geography.map(lambda x : 1 if x == 'France' else 0)
data['France'] = data['France'].astype('int64')

data['Spain'] = geography.map(lambda x : 1 if x == 'Spain' else 0)
data['Spain'] = data['Spain'].astype('int64')

data

X = data.drop(columns=['Exited'],axis=1)
Y=data['Exited']

from sklearn.model_selection import train_test_split

#param for total_UPDRS

X_train, X_test, y_train, y_test = train_test_split(X, Y,
    test_size=0.2, shuffle = True, random_state= 30)

from xgboost import XGBClassifier

model_dict = {
    'Logistic Regression' : LogisticRegression,
    'Random Forest' : RandomForestClassifier,
    'Ada Boost' : AdaBoostClassifier,
    'Gradient Boost' : GradientBoostingClassifier,
    'XG Boost' : XGBClassifier
}

model_score = pd.DataFrame()

for curr_model in model_dict:
    model = model_dict[curr_model]()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    model_score = model_score.append({  'Model' : curr_model,
                                        'Accuracy' : round(accuracy_score(y_test, y_pred),3),
                                        'Recall' : round(recall_score(y_test, y_pred),3),
                                        'Precision' : round(precision_score(y_test, y_pred),3),
                                        'F1 Score' : round(f1_score(y_test, y_pred),3)
                                        }, ignore_index=True)

model_score.head()

data

G=0
S=0
F=0

for a in range(len(data['Age'])):
  if data['Exited'][a] == 1 and data['France'][a]==1:
    F+=1
  elif data['Exited'][a] == 1 and data['Germany'][a]==1:
    G+=1
  elif data['Exited'][a] == 1 and data['Spain'][a]==1:
    S+=1

print(G)
print(S)
print(F)

M=0
F=0
for a in range(len(data['Age'])):
  if data['Exited'][a] == 1 and data['Male'][a]==1:
    M+=1
  elif data['Exited'][a] == 1 and data['Male'][a]==0:
    F+=1

print(M)
print(F)

C=0
N=0
for a in range(len(data['Age'])):
  if data['Exited'][a] == 1 and data['HasCrCard'][a]==1 and data['IsActiveMember'][a] ==1:
    C+=1
  elif data['Exited'][a] == 1 and data['HasCrCard'][a]==0 and data['IsActiveMember'][a] ==0:
    N+=1

print(C)
print(N)

data['LikelyToLeave'] = data.apply(lambda x : 1 if x['Male'] == 0 and (x['France']==1 or x['Germany']==1) else 0, axis = 1)
data['LikelyToLeave'] = data['LikelyToLeave'].astype('int64')

data.drop(columns = ['RowNumber','CustomerId'],axis = 1,  inplace = True)

data

X = data.drop(columns=['Exited'],axis=1)
Y=data['Exited']

X_train, X_test, y_train, y_test = train_test_split(X, Y,
    test_size=0.2, shuffle = True, random_state= 30)

model_score = pd.DataFrame()

for curr_model in model_dict:
    model = model_dict[curr_model]()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    model_score = model_score.append({  'Model' : curr_model,
                                        'Accuracy' : round(accuracy_score(y_test, y_pred),3),
                                        'Recall' : round(recall_score(y_test, y_pred),3),
                                        'Precision' : round(precision_score(y_test, y_pred),3),
                                        'F1 Score' : round(f1_score(y_test, y_pred),3)
                                        }, ignore_index=True)

model_score.head()

# C=0
# N=0
# for a in range(len(data['Age'])):
#   if data['Exited'][a] == 1 and data['HasCrCard'][a]==1 and data['IsActiveMember'][a] ==1:
#     C+=1
#   elif data['Exited'][a] == 1 and data['HasCrCard'][a]==0 and data['IsActiveMember'][a] ==0:
#     N+=1

C=0
N=0

for a in range(len(data['Age'])):
  if data['Exited'][a] == 1 and data['Age'][a] > data['Age'].median() and data['Balance'][a] > data['Balance'].median():
    C+=1
  # elif data['Exited'][a] == 1 and data['CreditScore'][a] < data['Balance'].median() and data['EstimatedSalary'][a] < data['EstimatedSalary'].median():
  #   N+=1

print(C)
print(N)

data['NotWorth'] = data.apply(lambda x :  (x['EstimatedSalary'] + x['Balance']) * x['Tenure'], axis = 1)

X = data.drop(columns=['Exited'],axis=1)
Y=data['Exited']

X_train, X_test, y_train, y_test = train_test_split(X, Y,
    test_size=0.2, shuffle = True, random_state= 30)

model_score = pd.DataFrame()

for curr_model in model_dict:
    model = model_dict[curr_model]()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    model_score = model_score.append({  'Model' : curr_model,
                                        'Accuracy' : round(accuracy_score(y_test, y_pred),3),
                                        'Recall' : round(recall_score(y_test, y_pred),3),
                                        'Precision' : round(precision_score(y_test, y_pred),3),
                                        'F1 Score' : round(f1_score(y_test, y_pred),3)
                                        }, ignore_index=True)

model_score.head()

data

data['EstimatedSalary']=data['EstimatedSalary']/max(data['EstimatedSalary'])
data['Balance']=data['Balance']/max(data['Balance'])
data['NotWorth']=data['NotWorth']/max(data['NotWorth'])

X = data.drop(columns=['Exited'],axis=1)
Y=data['Exited']

X_train, X_test, y_train, y_test = train_test_split(X, Y,
    test_size=0.2, shuffle = True, random_state= 30)

model_score = pd.DataFrame()

for curr_model in model_dict:
    model = model_dict[curr_model]()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    model_score = model_score.append({  'Model' : curr_model,
                                        'Accuracy' : round(accuracy_score(y_test, y_pred),3),
                                        'Recall' : round(recall_score(y_test, y_pred),3),
                                        'Precision' : round(precision_score(y_test, y_pred),3),
                                        'F1 Score' : round(f1_score(y_test, y_pred),3)
                                        }, ignore_index=True)

model_score.head()

max_recall = max(model_score['Recall'])
best_model = model_score[model_score['Recall'] == max_recall]['Model'].values[0]
print('Best model comes out to be {} with Recall: {}'.format(best_model,max_recall))
print('It will be selected for HyperParameter tuning.')

model_params = {
    'Logitic Regression' : {},
    'Random Forest' : {
        #random forest Parameters
        'n_estimators' : [50,75,100],
        'max_samples' : [.25,.5,.75],
        'max_features' : ['sqrt', 'log2'],

        #Base Estimator(DT) Parameters
        'criterion' : ['gini', 'entropy'],
        'max_depth' : [5,7,9,11],
        'min_samples_split' : [15, 20, 25],
        'min_samples_leaf' : [15, 20, 25]
    },
    'Ada Boost' : {
        'n_estimators' : [50, 75, 100, 125, 150],
        'learning_rate' : [0.001, 0.01, 0.05, 0.1, 1,5],
        'algorithm' : ['SAMME', 'SAMME.R']
    },
    'Gradient Boost' : {
        'learning_rate' : [0.01,0.1,0.5],
        'n_estimators' : [75, 100, 125],
        'min_samples_split' : [15,30,50],
        'min_samples_leaf' : [5,10,15,20],
        'max_depth' : [5,7,10],
        'min_impurity_decrease': [0.1, 0.3],
        'max_features': ['sqrt', 'log2']
    }
}

best_model_cv = RandomizedSearchCV(model_dict[best_model](), model_params[best_model], cv = 5,n_iter=50, scoring = 'accuracy')  #RandomSearch
best_model_cv.fit(X_train, y_train)


print('Best Hyper Parameters for {}: \n{}'.format(best_model, best_model_cv.best_params_))
print('Best score for {} using above Hyper Parameters: {}'.format(best_model, best_model_cv.best_score_))

# #Nie odpalaj tego
# best_model_cv = GridSearchCV(model_dict[best_model](), model_params[best_model], cv = 5, scoring = 'accuracy')  #GridSearchCV
# best_model_cv.fit(X_train, y_train)


# print('Best Hyper Parameters for {}: \n{}'.format(best_model, best_model_cv.best_params_))
# print('Best score for {} using above Hyper Parameters: {}'.format(best_model, best_model_cv.best_score_))

_best_model = model_dict[best_model](**best_model_cv.best_params_)
_best_model.fit(X_train,y_train)

y_pred = _best_model.predict(X_test)

#Evaluation Matrix
print('Accuracy score : ',accuracy_score(y_test, y_pred))
print('Recall score : ',recall_score(y_test, y_pred))
print('Precision score : ',precision_score(y_test, y_pred))
print('F1 score : ',f1_score(y_test, y_pred))

# sns.heatmap(data.corr(), annot=True)

plt.figure(figsize=(24, 12))
sns.heatmap(data.corr(), annot=True, fmt='.2f')
plt.xticks(rotation=55)
plt.show()

tn, fp , fn, tp = confusion_matrix(y_test, y_pred).ravel()

plt.figure(figsize = (5,3))
sns.heatmap(np.array([tp, fp , fn, tn]).reshape(2,2),xticklabels = [1,0],
            yticklabels = [1,0],fmt='d', annot = True,cmap="YlGnBu")
plt.title('Confusion Matrix')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')